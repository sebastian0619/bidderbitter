# BidderBitter 法律行业投标软件系统 - Cursor Rules

## 项目概述
这是一个法律行业的投标软件系统，用于管理获奖信息、业绩信息，并根据这些信息生成Word格式的投标文档。系统依赖AI进行文档解析、OCR识别、网页截图和数据结构化。

## 技术栈规范
任何的测试运行都应当通过docker compose 或者podman compose 不要直接在本地或者虚拟环境中运行
### 后端技术栈
- **框架**: FastAPI
- **ORM**: SQLAlchemy
- **数据库**: PostgreSQL
- **缓存**: Redis
- **AI/ML**: OpenAI API, Tesseract OCR
- **文档处理**: python-docx, PyMuPDF
- **Web自动化**: Selenium
- **容器化**: Docker/Podman

### 前端技术栈
- **框架**: Vue 3 (Composition API)
- **UI组件库**: Element Plus
- **构建工具**: Vite
- **状态管理**: Pinia
- **路由**: Vue Router
- **HTTP客户端**: Axios
- **样式**: SCSS

### 基础设施
- **容器编排**: Docker Compose
- **Web服务器**: Nginx
- **开发环境**: Podman (优先) / Docker

## 代码规范

### Python 后端规范
- 使用 Python 3.13
- 遵循 PEP 8 代码风格
- 使用类型注解 (Type Hints)
- 异步编程优先使用 async/await
- API 端点使用 FastAPI 装饰器和 Pydantic 模型
- 数据库模型使用 SQLAlchemy ORM
- 错误处理使用 FastAPI 的 HTTPException

### Vue 前端规范
- 使用 Vue 3 Composition API
- 组件命名使用 PascalCase
- 文件命名使用 kebab-case
- 使用 TypeScript 进行类型检查
- 组件结构：template -> script -> style
- 使用 Element Plus 组件库
- 状态管理使用 Pinia
- 路由使用 Vue Router

### 数据库规范
- 使用 PostgreSQL 作为主数据库
- 表名使用 snake_case
- 字段名使用 snake_case
- 主键统一使用 id
- 时间字段使用 created_at, updated_at
- 软删除使用 deleted_at

## 功能实现要求

### 核心功能模块

#### 1. 获奖信息管理
- 支持添加、编辑、删除获奖记录
- 包含奖项名称、颁发机构、获奖时间、证书文件等字段
- 支持证书文件上传和预览
- 支持按时间、机构等条件筛选
- **新增**: 支持按业务领域分类管理奖项
- **新增**: 支持奖项的深度检索和研究功能

#### 2. 业绩信息管理
- 支持添加、编辑、删除业绩记录
- 包含项目名称、客户名称、项目金额、完成时间、项目描述等字段
- 支持项目文件上传和预览
- 支持按客户、时间范围、金额等条件筛选

#### 3. 文档生成功能
- 支持基于获奖信息和业绩信息生成Word格式投标文档
- 使用 python-docx 库进行文档操作
- 支持模板化文档生成
- 支持自定义文档格式和样式

#### 4. AI 文档解析
- 支持 Word/PDF 文档解析
- 使用 PyMuPDF 进行 PDF 处理
- 使用 python-docx 进行 Word 文档处理
- 集成 OpenAI API 进行内容理解和结构化

#### 5. OCR 识别功能
- 使用 Tesseract OCR 进行图片文字识别
- 支持中文和英文识别
- 支持图片预处理和优化

#### 6. 网页截图功能
- 使用 Selenium 进行网页截图
- 支持动态页面截图
- 支持截图质量配置

### 高级功能模块

#### 7. 智能章节管理系统
- **章节类型识别**: 自动识别投标文档中的章节类型（如"荣誉奖项"、"业绩案例"等）
- **章节内容关联**: 在项目管理中直接关联对应的数据源
- **动态内容生成**: 根据章节类型自动从数据库检索和排列相关内容
- **智能推荐**: 基于章节要求推荐最相关的奖项和业绩信息

#### 8. AI自动检索奖项系统
- **多源数据检索**: 支持钱伯斯、Legal 500等权威法律评级网站
- **智能爬虫**: 使用Selenium + AI识别网页结构变化
- **精确检索**: 根据律师事务所名称、年份、业务领域进行精确检索
- **数据验证**: 自动验证检索结果的准确性和完整性
- **历史记录**: 保存检索历史，避免重复检索
- **批量检索**: 支持批量检索多个机构或年份

#### 9. 智能数据关联系统
- **跨模块数据关联**: 项目管理、奖项管理、业绩管理之间的智能关联
- **相似度匹配**: 使用AI算法匹配相似的项目和奖项
- **推荐引擎**: 基于历史数据推荐最合适的奖项和业绩组合
- **数据去重**: 自动识别和合并重复数据

#### 10. 高级搜索和分析系统
- **语义搜索**: 支持自然语言搜索奖项和业绩信息
- **多维度筛选**: 按时间、机构、金额、业务领域等多维度筛选
- **统计分析**: 提供数据统计和分析功能
- **趋势分析**: 分析获奖和业绩的时间趋势

### UI/UX 要求

#### 1. 响应式设计
- 支持桌面端和移动端
- 使用 Element Plus 的响应式组件
- 布局自适应不同屏幕尺寸

#### 2. 用户体验
- 加载状态提示
- 操作成功/失败反馈
- 表单验证和错误提示
- 数据表格支持搜索、排序、分页
- 文件上传支持拖拽和预览

#### 3. 界面布局
- 使用标签页布局管理不同功能模块
- 侧边栏导航
- 面包屑导航
- 数据统计卡片展示

#### 4. 智能交互设计
- **拖拽关联**: 支持拖拽方式关联章节和数据
- **智能提示**: 实时提示可用的相关数据
- **一键生成**: 一键生成完整的章节内容
- **实时预览**: 实时预览生成的文档内容

### 文件上传功能要求
- 支持拖拽上传
- 支持多文件上传
- 文件类型验证 (Word, PDF, 图片)
- 文件大小限制
- 上传进度显示
- 文件预览功能
- 上传失败重试机制

### 数据表格功能要求
- 支持搜索和过滤
- 支持排序
- 支持分页
- 支持批量操作
- 支持自定义列显示
- 支持数据导出

## 开发环境配置

### 容器化要求
- 优先使用 Podman 进行本地开发
- 提供 Docker 和 Podman 两种 Dockerfile
- 使用 Docker Compose 进行服务编排
- 环境变量配置化

### Conda环境配置
- **环境名称**: bidder
- **Python版本**: 3.11+
- **创建命令**: `conda create -n bidder python=3.11`
- **激活命令**: `conda activate bidder`
- **依赖安装**: 使用 `conda install` 或 `pip install` 在bidder环境中安装依赖
- **环境管理**: 所有Python依赖必须在bidder环境中安装

### 依赖管理
- Python 使用 requirements.txt
- Node.js 使用 package.json
- 使用国内镜像源加速下载
- 锁定依赖版本确保一致性

### 开发工具
- 使用 Vite 进行前端开发服务器
- 支持热重载
- 支持 TypeScript 编译
- 支持 SCSS 编译

## 错误处理和日志
- 统一的错误处理机制
- 详细的日志记录
- 用户友好的错误提示
- API 错误状态码规范

## 安全性要求
- API 接口权限控制
- 文件上传安全检查
- SQL 注入防护
- XSS 攻击防护
- CSRF 防护
- **新增**: 爬虫访问频率限制
- **新增**: 数据源访问权限控制

## 性能优化
- 数据库查询优化
- 前端资源压缩
- 图片懒加载
- API 响应缓存
- 分页加载大数据
- **新增**: 爬虫结果缓存
- **新增**: AI检索结果缓存

## 测试要求
- 单元测试覆盖核心功能
- 集成测试验证 API 接口
- 前端组件测试
- 端到端测试
- **新增**: 爬虫功能测试
- **新增**: AI检索准确性测试

## 部署要求
- 支持 Docker 容器化部署
- 支持 Podman 部署
- 环境变量配置
- 数据库迁移脚本
- 健康检查接口

## 文档要求
- API 文档使用 FastAPI 自动生成
- 代码注释规范
- README 文档完善
- 部署文档详细

## 代码提交规范
- 使用语义化提交信息
- 功能分支开发
- 代码审查流程
- 自动化测试集成

## 特殊注意事项
- 处理 PyMuPDF 安装的网络问题
- 配置国内镜像源加速构建
- 前端独立运行能力（后端未启动时）
- 错误重试和超时处理
- 文件上传大小限制配置
- **新增**: 爬虫反爬虫策略应对
- **新增**: AI检索结果准确性验证
- **新增**: 数据源网站结构变化监控 